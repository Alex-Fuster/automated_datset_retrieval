---
title: "Evaluating the feasibility of automating dataset retrieval for biodiversity monitoring"
Authors: Alexandre Fuster-Calvo, Sarah Valentin, William Cabrera, Dominique Gravel

---


This script manipulates the raw data of the retrieved datasets to show summary tables and figures.


```{r}
library(dplyr)
library(reshape)
library(ggplot2)
library(hrbrthemes)
library(ggpubr)
library(tidyr)
library(stringr)
library(ggrepel)
library(readxl)
library(forcats)

source("Functions.R")
```



Some parameters for plotting:

```{r}
my.theme<-theme(axis.text=element_text(size=15),
        axis.title = element_text(size = 17),
        legend.text=element_text(size=10),
        legend.title = element_text(size=12),
        plot.title = element_text(face="bold",size=14,margin=margin(0,0,20,0),hjust = 0.5),
        axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)),
        axis.title.x = element_text(margin = margin(t = 15, r = 0, b = 0, l = 0)),
        panel.background = element_rect(fill = 'white'))

```




#### Read data

```{r}

dataset <- read_excel("../data/dataset_092624.xlsx")

dataset_repos <- dataset %>%
  filter(!(source %in% c("semantic_scholar", "referenced")))

```



#### Overlap between queries

```{r}

query_sets <- lapply(0:10, function(i) {
  query_ids <- which(grepl(paste0("\\b", i, "\\b"), dataset_repos$id_query))
  return(query_ids)
})


# Initialize a matrix to store the overlap percentages
overlap_matrix <- matrix(0, nrow = 11, ncol = 11)

# Calculate the overlap percentage between each pair of queries
for (i in 1:length(query_sets)) {
  for (j in 1:length(query_sets)) {
    if (i != j) {
      overlap <- length(intersect(query_sets[[i]], query_sets[[j]]))
      overlap_percentage <- (overlap / (length(query_sets[[i]]) + length(query_sets[[j]]) - overlap)) * 100
      overlap_matrix[i, j] <- overlap_percentage
    }
  }
}


# Round values
overlap_matrix = round(overlap_matrix, 1)


# Add queries' names

query_names = c(
"survey + species",
"time series + species",
"inventory + species",
"species",
"abundance + species",
"occurrence + species",
"population + species",
"sites + species",
"sampling + species",
"collection + species",
"density + species"
  
)

colnames(overlap_matrix) = query_names
rownames(overlap_matrix) = query_names


# Get only the upper triangle

upper_triangle <- overlap_matrix
upper_triangle[lower.tri(upper_triangle)] <- 0

upper_triangle_df <- as.data.frame(as.table(upper_triangle))
names(upper_triangle_df) <- c("row", "col", "value")
upper_triangle_df <- upper_triangle_df[upper_triangle_df$row != upper_triangle_df$col, ]


# Plot triangle heatmap

plot_overlap_queries = ggplot(upper_triangle_df, aes(x = col, y = row, fill = value)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  labs(x = NULL, y = NULL, fill = "% overlap")


plot_overlap_queries

#ggsave("../figures/plot_overlap_queries.png", height = 5, width = 6)

```



Count Valid/non-valid datasets:

```{r}
table(dataset_repos$valid_yn)
```

Count reasons for non-valid assignment:

```{r}
table(dataset_repos$reason_non_valid[which(dataset_repos$valid_yn=="no")])
```

Discard non-valid, non-accessible, or non-existent datasets
Format columns

```{r}

dataset_repos_assessed <- dataset_repos |>
  dplyr::filter(valid_yn == "yes") |>
  dplyr::filter(MC_relevance != "") |>
  dplyr::mutate(
    MC_relevance = as.factor(MC_relevance),
    MC_relevance_modifiers = as.factor(MC_relevance_modifiers),
    id_query = stringr::str_trim(id_query),
    MC_relevance = stringr::str_trim(MC_relevance),
    MC_relevance_modifiers = stringr::str_trim(MC_relevance_modifiers)
  )


head(dataset_repos_assessed)
```

# 1. Number of datasets and relevance categories

```{r}

# total retrieved datasets from repositories
n_retrieved_repos <- nrow(dataset_repos)

# Count and calculate percentages for MC_relevance, labeled as MC_mainc_relevance
relevance_mainc_table <- dataset_repos_assessed |>
  dplyr::count(MC_relevance) |>
  dplyr::mutate(
    MC_mainc_relevance = factor(MC_relevance, levels = c("H", "M", "L", "X")),
    percentage_mainc_relevance = (n / n_retrieved_repos) * 100
  ) |>
  dplyr::select(MC_mainc_relevance, n_mainc_relevance = n, percentage_mainc_relevance) |>
  dplyr::arrange(MC_mainc_relevance)

# Count and calculate percentages for MC_relevance_modifiers
relevance_modifiers_table <- dataset_repos_assessed |>
  dplyr::count(MC_relevance_modifiers) |>
  dplyr::mutate(
    MC_relevance_modifiers = factor(MC_relevance_modifiers, levels = c("H", "M", "L", "X")),
    percentage_relevance_modifiers = (n / n_retrieved_repos) * 100
  ) |>
  dplyr::select(MC_relevance_modifiers, n_relevance_modifiers = n, percentage_relevance_modifiers) |>
  dplyr::arrange(MC_relevance_modifiers)

# Merge the two tables by matching the row order
merged_table <- dplyr::bind_cols(relevance_mainc_table, relevance_modifiers_table)

# Display the resulting merged table
print(merged_table)
```


# 2. Queries performance

### 2.1. N publications and relevance categories per query

```{r}

convert_query = data.frame("id_query" = as.character(seq(0,10)), "query" = c(
"survey + species",
"time series + species",
"inventory + species",
"species",
"abundance + species",
"occurrence + species",
"population + species",
"sites + species",
"sampling + species",
"collection + species",
"density + species"
  
))


#split rows in function of character comas

dataset_query <- dataset_repos %>%               
  separate_rows(id_query, sep=",") 


dataset_query <- merge(dataset_query, convert_query, by.all="id_query")


dataset_query$query  <- factor(dataset_query$query,
                           levels= c("species", "occurrence + species",
                                     "inventory + species", "collection + species",
                                     "sampling + species", "survey + species" , 
                                     "population + species", "sites + species", 
                                     "density + species", "abundance + species",
                                     "time series + species" ))


df_queries_counts_ind <- dataset_query %>% 
  group_by(MC_relevance_modifiers, query) %>% 
  summarise(n = n())  %>% 
  dplyr::filter(MC_relevance_modifiers %in% c("X", "L", "M", "H")) %>% 
  mutate(MC_relevance_modifiers = factor(MC_relevance_modifiers))


df_queries_counts_ind



```



Plot the results:

```{r}


plot_queries_relevance_counts <- ggplot(df_queries_counts_ind, 
                                          aes(x=query, y=n, group = MC_relevance_modifiers, 
                                              color = MC_relevance_modifiers,shape=MC_relevance_modifiers )) +
  geom_segment( aes(x=query ,xend=query, y=0, yend=max(n)), color="grey") +
    geom_point(size=4, alpha = 0.8) +
    coord_flip() +
    # theme_ipsum() +
    theme(
      panel.grid.minor.y = element_blank(),
      panel.grid.major.y = element_blank(),
      legend.position="top"
    ) +
    xlab("Query ID")+
    ylab("publications counts") +
    scale_color_manual(name = "dataset relevance",
                       values = c( "red","purple2", "dodgerblue", "black"))+
    scale_shape_manual(name = "dataset relevance", 
                       values = c(19, 19, 19, 1))+
    my.theme



plot_queries_relevance_counts

```

### 2.2. F SCORE


```{r}

df_zscores_queries <- calculate_z.score_queries(df = dataset_repos)

df_zscores_queries$Fscore <- round(df_zscores_queries$Fscore, 2)
df_zscores_queries$Precision <- round(df_zscores_queries$Precision, 2)
df_zscores_queries$Recall <- round(df_zscores_queries$Recall, 2)


df_zscores_queries

```

Plot results:

```{r}

mid = mean(df_zscores_queries$Fscore)

plot_queries_scores <- ggplot(df_zscores_queries, aes(x = Precision, y = Recall, colour = Fscore)) +
  geom_point(size = 10)+
  geom_label_repel(aes(label = query),alpha = 0.75, 
                   label.padding=.1)+
  scale_color_gradient2(midpoint=mid, low="dodgerblue", mid="purple2",
                     high="red", space ="Lab" )+
  theme_bw()+
  my.theme

plot_queries_scores

```

```{r}

combined_plot_queries <- ggarrange(plot_queries_relevance_counts,
                                   plot_queries_scores, 
                                   nrow = 1,
                                   ncol = 2)

combined_plot_queries

#ggsave("../figures/combined_plot_queries.png",height = 6,width = 13)

```


# ANALYSES OF RELEVANT DATASETS

Discard datasets with negligible relevance for all the analyses from here in advance.

```{r}
dataset_repos_relevant <- dataset_repos_assessed[dataset_repos_assessed$MC_relevance_modifiers != "X",]

# total number of relevant datasets

n_repos_relevant <- nrow(dataset_repos_relevant)
```


# 3. Temporal range and duration


```{r}

# how many datasets with temporal range information

print(paste(length(which(dataset_repos_relevant$temporal_range_position == "not given")), "publications without temporal range data.", length(which(dataset_repos_relevant$temporal_range_position == "not given"))/n_repos_relevant*100, "%"))
```

### 3.1 Temporal range

```{r}

# Select variables of interest

dataset_temp_range <- dataset_repos_relevant[,c("url", "temp_range_i", "temp_range_f", "time_series")]

# Eliminate Nas

dataset_temp_range <- dataset_temp_range[-which(is.na(dataset_temp_range$temp_range_i)),]

dataset_temp_range <- as.data.frame((dataset_temp_range))

dataset_temp_range$temp_range_i <- as.numeric(dataset_temp_range$temp_range_i)
dataset_temp_range$temp_range_f <- as.numeric(dataset_temp_range$temp_range_f)

print(paste(nrow(dataset_temp_range), "with temporal range data"))


# Eliminate outlier

dataset_temp_range <- dataset_temp_range[-which(dataset_temp_range$temp_range_i == -20000),]

dataset_temp_range[which(dataset_temp_range$temp_range_i == dataset_temp_range$temp_range_f),"temp_range_f"] <- dataset_temp_range[which(dataset_temp_range$temp_range_i == dataset_temp_range$temp_range_f),"temp_range_f"]+0.5

# cut lower limit range for outlier

dataset_temp_range$temp_range_i[which(dataset_temp_range$temp_range_i < 1930)] <- 1930



```

Plot the results:

```{r}

p_temp_range <- ggplot(dataset_temp_range, aes(y=url, color = time_series)) +
  geom_segment(aes(x=temp_range_i, xend=temp_range_f, y=url, yend=url), linewidth=3)+
  xlab("year") +
  ylab ("datasets")+
  #theme_bw() +
  my.theme +
  theme(axis.text.y=element_blank())+
  scale_color_manual(values = c("gray37", "#F8766D"))+
  theme(legend.position = "none") +
  xlim(1930, round(max(dataset_temp_range$temp_range_f),0))+
  geom_label(
    label="1875", 
    x=1930,
    y=5,
    #label.padding = unit(0.2, "lines"), # Rectangle size around label
    label.size = 0.1,
    color = "black"
   # fill="white"
  )

p_temp_range

```


### 3.2 Temporal duration counts

How many publications without temporal duration data?

```{r}

print(paste(length(which(dataset_repos_relevant$temporal_duration_position == "not given")), "publications without temporal duration data.",
            length(which(dataset_repos_relevant$temporal_duration_position == "not given"))/n_repos_relevant*100, "%"))

```

Publication counts by temporal duration (years):

```{r}
  
df_duration_counts <- count_durations(df = dataset, order_by = "counts")

df_duration_counts
```

Plot the results:

```{r}
plot_temp_duration <- plot_duration_counts(df = df_duration_counts, 
                                           counts_Na = nNa)

plot_temp_duration


```

Average duration (for those with data):

```{r}

dataset_temp_duration <- subset(dataset_repos_relevant, 
                                  temporal_duration_y > 0 | temporal_duration_y == "not given",
                                  select = c(temporal_duration_y,id_query))
  
  dataset_temp_duration$temporal_duration_y <- as.numeric(dataset_temp_duration$temporal_duration_y)
  

print(paste("mean of",
            round(mean(na.omit(dataset_temp_duration$temporal_duration_y)),digits = 1),
            "years"))
```

# 4. Spatial range

### 4.1 count spatial range publications

Publications that cant be accessed are not counted.

How many publications without spatial range data?

```{r}

n_not_reported <- count_not.reported_spatial_range(dataset_repos_relevant)

print(paste(n_not_reported, "publications without spatial range data.",
            n_not_reported/n_repos_relevant*100, "%"))

```

Average spatial range:

```{r}

# Convert spatial_range_km2 to numeric and compute the mean
dataset_repos_relevant <- dataset_repos_relevant |>
  dplyr::mutate(spatial_range_km2_numeric = as.numeric(spatial_range_km2)) 

# Compute the mean of the numeric column, excluding NA values
mean_spatial_range_km2 <- dataset_repos_relevant |>
  dplyr::summarise(mean_value = mean(spatial_range_km2_numeric, na.rm = TRUE))

# Display the mean
print(mean_spatial_range_km2)
```

Plot the results: Spatial ranges are divided according to the thresholds established to determine a low, moredate and high spatial range: \<5000, 500-15000, \>15000

```{r}

plot_spatial_range_counts <- plot_spat.range_counts(dataset_repos_assessed)+
  coord_flip()

plot_spatial_range_counts

```





```{r}
print(paste(length(which(dataset_repos_assessed$geospatial_info_repo_page_text == "not given")), "publications without spatial range data in the repository.",
            length(which(dataset_repos_assessed$geospatial_info_repo_page_text == "not given"))/n_repos_relevant*100, "%"))

```





#### Temporal duration, spatial range, relevance

```{r}

plot_spatial_temporal_relevance <- plot_spat_temp_relevance(df = dataset_repos_relevant)

plot_spatial_temporal_relevance

```

# 5. EBV data types

```{r}

df_data_type_counts <- compute_df_data.type(df = dataset_repos_relevant)

df_data_type_counts 

```

Plot the results

```{r}

plot_data_type <- plot_data.type_counts(df_data_type_counts)+
  coord_flip()

plot_data_type

```

### Combine plots

```{r}

plot_combined_corpus <- ggarrange(
p_temp_range,
plot_spatial_temporal_relevance,
plot_data_type,
plot_spatial_range_counts,
nrow = 2,
ncol = 2,
  labels = c("a", "b", "c","d"),
font.label = list(size = 24),
heights = c(1,0.6))

plot_combined_corpus

#ggsave("../figures/plot_combined_corpus.png", height = 10, width = 12)
```


# 7. Location of information - features

### 7.1 % data type in abstract and title

Synonyms for the different EBV data type categories:

```{r}
df_dataset_types <- read.csv("../data/dataset_types.csv", sep = ",")
df_dataset_types
```

```{r}
df_dataset_types[nrow(df_dataset_types)+1,] <- c("presence-absence", "detection", "synonym")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("presence-absence", "capture", "synonym")

df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "16S", "methods")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "18S", "methods")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "barcodes", "methods")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "haplotypes", "methods")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "eDNA", "methods")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "SNPs", "methods")

df_dataset_types
```

```{r}

url <- c()
dataset_type <- c()
keyword_abs <- list()
keyword_title <- list()
#keyword_type <- c()
in_title <- c()
in_abstract <- c()


for (i in 1:nrow(dataset_repos_relevant)) {
  
  
  
  dataset_type[i] <- dataset_repos_relevant[i, "data_type"]
  url[i] <- dataset_repos_relevant[i, "url"]
  
  
  
  
  # search on the abstract and note the list of keywords that match the dataset types

  keyword_abs[[i]] <- unique(get_keywords(input_string = dataset_repos_relevant$full_text[i], 
               dataset_types =  df_dataset_types))
  
  # if the list of keywords has 1 or more entry, then note that we found information in the abstract
  
  if(length(keyword_abs[i][!sapply(keyword_abs[i], is.null)]) == 0){
    
    in_abstract[i] <- "no"
    
  } else if (length(keyword_abs[i][!sapply(keyword_abs[i], is.null)]) > 0){
    
    in_abstract[i] <- "yes"
    
  }
  
  
  

  # search on the title and note the list of keywords that match the dataset types

  keyword_title[[i]] <- unique(get_keywords(input_string = dataset_repos_relevant$title[i], 
               dataset_types =  df_dataset_types))
  
  # if the list of keywords has 1 or more entry, then note that we found information in the abstract
  
  if(length(keyword_title[i][!sapply(keyword_title[i], is.null)]) == 0){
    
    in_title[i] <- "no"
    
  } else if (length(keyword_title[i][!sapply(keyword_title[i], is.null)]) > 0){
    
    in_title[i] <- "yes"
    
  } 
  
  
  
}


dataset_repos_relevant$data.type_in_abstract <- in_abstract
dataset_repos_relevant$data_type_in_title <- in_title



print(paste(length(which(in_abstract == "yes")), 
            "with dataset type or synonym explicit in the abstract, out of", length(in_abstract)))

print(paste("so", 
      round(length(which(in_abstract == "yes"))/length(in_abstract)*100, 1),
"%"))

print(paste(length(which(in_title == "yes")), 
            "with dataset type or synonym explicit in the title, out of", length(in_title)))

print(paste("so", 
      round(length(which(in_title == "yes"))/length(in_title)*100, 1),
"%"))



```

### 7.2 Temporal range and duration, spatial range, species, and data type location

```{r}


df_features.l <- dataset_repos_relevant[,c("temporal_range_position", "temporal_duration_position", "spatial_range_position", "data.type_in_abstract", "data_type_in_title")]

# add id

df_features.l$id <- c(1:nrow(df_features.l))



# separate by commas

df_features.l1 <- df_features.l %>%               
  separate_rows(temporal_range_position, sep=",") %>% 
  separate_rows(temporal_duration_position, sep=",") %>% 
  separate_rows(spatial_range_position, sep=",")



# Homogenize levels

levels(as.factor(df_features.l1$species_location))


df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == " source link")] <- "repository text"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == "source link")] <- "repository text"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == "source link abstract")] <- "repository text"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == " dataset")] <- "dataset"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == " source publication text")] <- "article"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == "source publication text")] <- "article"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == "no")] <- "not given"



df_features.l1$temporal_duration_position[which(df_features.l1$temporal_duration_position == "source link")] <- "repository text"
df_features.l1$temporal_duration_position[which(df_features.l1$temporal_duration_position == "source link abstract")] <- "repository text"
df_features.l1$temporal_duration_position[which(df_features.l1$temporal_duration_position == "source publication text")] <- "article"
df_features.l1$temporal_duration_position[which(df_features.l1$temporal_duration_position == "no")] <- "not given"



df_features.l1$spatial_range_position[which(df_features.l1$spatial_range_position == "source link")] <- "repository text"
df_features.l1$spatial_range_position[which(df_features.l1$spatial_range_position == "source link abstract")] <- "repository text"
df_features.l1$spatial_range_position[which(df_features.l1$spatial_range_position == "source publication text")] <- "article"
df_features.l1$spatial_range_position[which(df_features.l1$spatial_range_position == "no")] <- "not given"


df_features.l1

```

How many with all the features readily accessible (in repository text):

```{r}
n_all <- nrow(na.omit(df_features.l1[ 
                   df_features.l1$data.type_in_abstract == "yes" & 
                   df_features.l1$temporal_range_position == 'repository text' &
                   df_features.l1$spatial_range_position == 'repository text',]))

print(paste(n_all, "with all the features readily accessible (in the repository text) - a", round(n_all/n_repos_relevant*100, 3),"%"))

```

How many with at least one feature accessible

```{r}

df_features.l2 <- df_features.l1[!is.na(df_features.l1$data.type_in_abstract),]

df_features.l2 <- df_features.l1[ 
  df_features.l1$data_type_in_title == "yes" |
                   df_features.l1$data.type_in_abstract == "yes" |
                   df_features.l1$temporal_range_position == 'repository text' |
                   df_features.l1$spatial_range_position == 'repository text', ]

df_features.l2 <- df_features.l2[!is.na(df_features.l2$data.type_in_abstract),]
n_any <- length(unique(df_features.l2$id))

print(paste(n_any, "with at least one feature readily accessible (in the repository text) - a", round(n_any/n_repos_relevant*100, 3),"%"))

```


```{r}


df_locations_plot <- count_position_features(dataset_repos_relevant)

df_locations_plot <- df_locations_plot[!is.na(df_locations_plot$location), ]



plot_location_features <- ggplot(df_locations_plot, aes(x=location, y = Freq, group = feature)) +
   geom_segment( aes(x=location ,xend=location, y=0, yend=max(Freq)), color="grey") +
    geom_point(aes(shape = feature),size=4, alpha = 0.8) +
    coord_flip() +
  theme_bw() +
  my.theme+
  #scale_color_manual(values = c("deepskyblue2","firebrick1","indianred4"))+
  scale_shape_manual(values = c(16,8,2))+
  ylab("publication counts")+
  theme(legend.position = "top")

plot_location_features

```

#8. Spatial information format

```{r}

# Eliminate Nas

geospatial_info_article_text <- dataset_repos_relevant$geospatial_info_article_text[-which(is.na(dataset_repos_relevant$geospatial_info_article_text))]

geospatial_info_dataset <- dataset_repos_relevant$geospatial_info_dataset[-which(is.na(dataset_repos_relevant$geospatial_info_dataset))]

geospatial_info_repo_page_text <- dataset_repos_relevant$geospatial_info_repo_page_text[-which(is.na(dataset_repos_relevant$geospatial_info_repo_page_text))]


# Separate by commas

geospatial_info_article_text  <- unlist(strsplit(geospatial_info_article_text,","))

geospatial_info_dataset  <- unlist(strsplit(geospatial_info_dataset,","))

geospatial_info_repo_page_text  <- unlist(strsplit(geospatial_info_repo_page_text,","))



# Homogenize names

## column geospatial_info_article_text

geospatial_info_article_text[which(geospatial_info_article_text == " administrative unit")] <- "administrative unit"
geospatial_info_article_text[which(geospatial_info_article_text == " range coordites")] <- "range coordinates"
geospatial_info_article_text[which(geospatial_info_article_text == " site coordites")] <- "site coordinates"
geospatial_info_article_text[which(geospatial_info_article_text == "site coordites")] <- "site coordinates"
geospatial_info_article_text[which(geospatial_info_article_text == " geological feature me")] <- "geographic feature"
geospatial_info_article_text[which(geospatial_info_article_text == "geological feature me")] <- "geographic feature"
geospatial_info_article_text[which(geospatial_info_article_text == " Map")] <- "Map"
geospatial_info_article_text[which(geospatial_info_article_text == "Map")] <- "map"
geospatial_info_article_text[which(geospatial_info_article_text == "administration unit")] <- "administrative unit"
geospatial_info_article_text[which(geospatial_info_article_text == "Administrative unit")] <- "administrative unit"
geospatial_info_article_text[which(geospatial_info_article_text == "no")] <- "not given"


## column geospatial_info_dataset

geospatial_info_dataset[which(geospatial_info_dataset == " site coordites")] <- "site coordinates"
geospatial_info_dataset[which(geospatial_info_dataset == "  site coordites")] <- "site coordinates"
geospatial_info_dataset[which(geospatial_info_dataset == "site coordites")] <- "site coordinates"
geospatial_info_dataset[which(geospatial_info_dataset == "sample coordites")] <- "sample coordinates"
geospatial_info_dataset[which(geospatial_info_dataset == " sample coordites")] <- "sample coordinates"
geospatial_info_dataset[which(geospatial_info_dataset == " administrative unit")] <- "administrative unit"
geospatial_info_dataset[which(geospatial_info_dataset == " site IDs")] <- "site IDs"
geospatial_info_dataset[which(geospatial_info_dataset == " IDs")] <- "site IDs"
geospatial_info_dataset[which(geospatial_info_dataset == " geographic feature")] <- "geographic feature"
geospatial_info_dataset[which(geospatial_info_dataset == "no")] <- "not given"



## column geospatial_info_repo_page_text

geospatial_info_repo_page_text[which(geospatial_info_repo_page_text == "geological feature me")] <- "geographic feature"
geospatial_info_repo_page_text[which(geospatial_info_repo_page_text == "Administrative unit")] <- "administrative unit"
geospatial_info_repo_page_text[which(geospatial_info_repo_page_text == "no")] <- "not given"

```

```{r}

# Make dataframe with counts

location <- rep("article text", times = length(geospatial_info_article_text))

df_article <- data.frame(geospatial_info_article_text, location)

location <- rep("repository page", times = length(geospatial_info_repo_page_text))

df_repo<- data.frame(geospatial_info_repo_page_text, location)

location <- rep("dataset", times = length(geospatial_info_dataset))

df_dataset <- data.frame(geospatial_info_dataset, location)

colnames(df_article) <- c("information", "location")
colnames(df_repo) <- c("information", "location")
colnames(df_dataset) <- c("information", "location")

df_locations <- rbind(df_article,df_repo,df_dataset)

df_locations$information[which(df_locations$information == "site IDs") ] <- "sites IDs"
df_locations$information[which(df_locations$information == "site coordites") ] <- "site coordinates"
df_locations$information[which(df_locations$information == "Map") ] <- "map"
df_locations$information[which(df_locations$information == "geologial feature") ] <- "geographic feature"
df_locations$information[which(df_locations$information == "geographical feature") ] <- "geographic feature"

```


Plot results

```{r}

df_locations <- as.data.frame(table(df_locations))


df_locations$location <- factor(df_locations$location, levels=c("article text", "repository page", "dataset"))

df_locations$information <- factor(df_locations$information, levels=c("not given", "sites IDs", "map", "administrative unit", "geographic feature", "distribution model", "range coordinates", "site coordinates", "sample coordinates"))

df_filtered <- df_locations %>% filter(!is.na(information))

plot_location_type_geoinfo <- ggplot(df_filtered, aes(x=information, y = Freq, group = location, color = location)) +
   geom_segment( aes(x=information ,xend=information, y=0, yend=max(Freq)), color="grey") +
    geom_point(size=4, alpha = 0.5, aes(shape = location)) +
    coord_flip() +
  theme_bw() +
  my.theme+
  scale_shape_manual(values = c(15,8,21))+
  scale_color_manual(values = c("black", "black", "black"))+
  ylab("publication counts")+
  xlab("precision")+
  theme(legend.position = "top")


plot_location_type_geoinfo



```



```{r}
plot_location_inf <- ggarrange(
  
  plot_location_features,
  plot_location_type_geoinfo,
  
  nrow = 1,
  ncol = 2,
  
  labels = c("A", "B")
  
)

plot_location_inf


#ggsave("plot_location_inf.png", height = 5, width = 13)

```




# 9. Taxa (repositories)

```{r}

df_taxa <- read_excel(here::here("data/df_taxa_fig.xlsx"))

df_taxa <- df_taxa |>
  dplyr::left_join(
    dataset_repos_relevant |> 
      dplyr::select(url, MC_relevance_modifiers),  # Select only relevant columns from dataset_repos_relevant
    by = "url"
  ) |>
  dplyr::filter(!is.na(MC_relevance_modifiers)) |> # remove non-relevant datasets
  dplyr::mutate( #Remove spaces from fewspp_group and multispp_group columns
    fewspp_group = stringr::str_trim(fewspp_group),
    multispp_group = stringr::str_trim(multispp_group)
  )

# eliminate those without relevance in MC_relevance_modifier
# correct spaces in the fewspp_group and multispp_group

df_taxa$fewspp_group[which(df_taxa$fewspp_group == "Mammalia\xa0")] <- "Mammalia"
df_taxa$fewspp_group[which(df_taxa$fewspp_group == "Amphibia\xa0")] <- "Amphibia"
df_taxa$fewspp_group[which(df_taxa$fewspp_group == "Osteichthyes")] <- "Fish"

df_taxa_spp <- df_taxa[which(df_taxa$fewspp_group != ""),]

df_taxa_spp$fewspp_group <- as.factor(df_taxa_spp$fewspp_group)


df_taxa_spp$MC_relevance_modifiers <- factor(df_taxa_spp$MC_relevance_modifiers, levels = c("H", "M", "L"))

plot_spp <- ggplot(df_taxa_spp, aes(x = fewspp_group, group = MC_relevance_modifiers, fill = dataset_relevance)) +
  geom_bar(aes(x = forcats::fct_infreq(fewspp_group), fill = MC_relevance_modifiers))+
  my.theme+
  coord_flip()+
    xlab("")+
    ylab("publications counts") +
    ggtitle("Species-level studies")+
    scale_fill_manual(name = "dataset relevance",
                       values = alpha(c("red","purple2", "dodgerblue"), .7))+
 # theme_bw()+
    my.theme


df_taxa$multispp_group[which(df_taxa$multispp_group == "Mammalia\xa0")] <- "Mammalia"
df_taxa$multispp_group[which(df_taxa$multispp_group == "Osteichthyes")] <- "Fish"
df_taxa_comm <- df_taxa[which(df_taxa$multispp_group != ""),]


df_taxa_comm$multispp_group <- as.factor(df_taxa_comm$multispp_group)
df_taxa_comm$n <- as.numeric(df_taxa_comm$n)

df_taxa_comm$n[which(df_taxa_comm$n == 1)] <- 2
df_taxa_comm$n[which(df_taxa_comm$n == 2)] <- 3

df_taxa_comm <- df_taxa_comm[order(-df_taxa_comm$n), ]


df_taxa_comm$MC_relevance_modifiers <- factor(df_taxa_comm$MC_relevance_modifiers, levels = c("H", "M", "L"))

plot_comm <- ggplot(df_taxa_comm, aes(x = multispp_group, y = n, fill = MC_relevance_modifiers)) +
   geom_bar(stat = "identity", position = position_dodge2(preserve = "total"),  color = "white")+
  coord_flip()+
  ggtitle("Community-level studies")+
    xlab("")+
    ylab("N taxa") +
    scale_fill_manual(name = "dataset relevance",
                       values = alpha(c("red","purple2", "dodgerblue"), .7))+
  scale_y_continuous(limits = c(0, max(df_taxa_comm$n)), breaks = c(25,50,75, 100, 125, 150, 175))+
 # theme_bw()+
    my.theme


# Cap the 'n' values at 180 for plotting
df_taxa_comm_capped <- df_taxa_comm |>
  mutate(n_capped = ifelse(n > 180, 180, n))  # Cap n at 180 for plotting

# Create the plot with capped values and label for the bar that exceeds 180
plot_comm <- ggplot(df_taxa_comm_capped, aes(x = multispp_group, y = n_capped, fill = MC_relevance_modifiers)) +
  geom_bar(stat = "identity", position = position_dodge2(preserve = "total"), color = "white") +
  coord_flip() +
  ggtitle("Community-level studies") +
  xlab("") +
  ylab("N taxa") +
  scale_fill_manual(name = "dataset relevance",
                    values = alpha(c("red", "purple2", "dodgerblue"), .7)) +
  scale_y_continuous(limits = c(0, 180), breaks = c(25, 50, 75, 100, 125, 150, 175)) +
  my.theme

#Add a label to the bar that exceeds 180 (n = 439)
plot_comm <- plot_comm +
  geom_text(data = df_taxa_comm_capped %>% filter(n > 180), 
            aes(label = "(439)", y = 165),  # Place label at the y-axis limit (180)
            nudge_y = -10,
            hjust = -0.01, size = 4, color = "black")  # Adjust label position and size

# Step 4: Display the plot
print(plot_comm)



plots_taxa <- ggarrange(plot_spp,
          plot_comm,
          common.legend = TRUE)

plots_taxa

#ggsave(here::here("figures/plots_taxa.png"), height = 8, width = 11)

```




######################################################### 


# 10. SEMANTIC SCHOLAR


#### Read data

```{r}

dataset_sc <- dataset[dataset$source == "semantic_scholar" & dataset$source != " ",]

```

```{r}

table(dataset_sc$valid_yn)

```

```{r}

table(dataset_sc$reason_non_valid[which(dataset_sc$valid_yn=="no")])
```



### 10.1. Number of datasets and relevance categories

select only valid publications

```{r}
dataset_sc <- dataset_sc %>% dplyr::filter(valid_yn == "yes")
```


Count relevance

```{r}

# total retrieved datasets from repositories
dataset_sc_assessed <- dataset_sc |>
  dplyr::filter(MC_relevance_modifiers %in% c("H", "M", "L", "X"))

n_retrieved_sc <- nrow(dataset_sc_assessed)

# Count and calculate percentages for MC_relevance, labeled as MC_mainc_relevance
relevance_mainc_table <- dataset_sc_assessed |>
  dplyr::count(MC_relevance) |>
  dplyr::mutate(
    MC_mainc_relevance = factor(MC_relevance, levels = c("H", "M", "L", "X")),
    percentage_mainc_relevance = (n / n_retrieved_sc) * 100
  ) |>
  dplyr::select(MC_mainc_relevance, n_mainc_relevance = n, percentage_mainc_relevance) |>
  dplyr::arrange(MC_mainc_relevance)

# Count and calculate percentages for MC_relevance_modifiers
relevance_modifiers_table <- dataset_repos_assessed |>
  dplyr::count(MC_relevance_modifiers) |>
  dplyr::mutate(
    MC_relevance_modifiers = factor(MC_relevance_modifiers, levels = c("H", "M", "L", "X")),
    percentage_relevance_modifiers = (n / n_retrieved_sc) * 100
  ) |>
  dplyr::select(MC_relevance_modifiers, n_relevance_modifiers = n, percentage_relevance_modifiers) |>
  dplyr::arrange(MC_relevance_modifiers)

# Merge the two tables by matching the row order
merged_table <- dplyr::bind_cols(relevance_mainc_table, relevance_modifiers_table)

# Display the resulting merged table
print(merged_table)
```

### 10.2 Relevance counts by source


```{r}

dataset <- read_excel("../data/dataset_092624.xlsx")
dataset <- dataset[which(dataset$MC_relevance_modifiers != ""),]
dataset <- dataset %>% dplyr::filter(valid_yn == "yes") |> 
  dplyr::filter(source != "referenced")

dataset$MC_relevance_modifiers[which(dataset$MC_relevance_modifiers == "cant access")] <- "No access"

df_rel_source <- count_relevance_by_source(df = dataset)

df_rel_source$repositories <- df_rel_source$dryad + df_rel_source$zenodo

df_rel_source


```

Plot the results:

```{r}

df_rel_source_melt <- melt(df_rel_source, id ="relevance")
colnames(df_rel_source_melt) <- c("relevance", "source", "value")


plot_relevance_source <- ggplot(df_rel_source_melt, 
                                          aes(x=relevance, y=value, group = source, 
                                              color = source,
                                              alpha=source)) +
  scale_x_discrete(limits = rev(levels(df_rel_source_melt$relevance)))+
    geom_segment( aes(x=relevance ,xend=relevance, y=0, yend=max(value)), color="grey") +
    geom_point(aes(shape = source),size = 5) + #alpha = 0.8, 
    coord_flip() +
    # theme_ipsum() +
    theme(
      panel.grid.minor.y = element_blank(),
      panel.grid.major.y = element_blank(),
      legend.position="top"
    ) +
    xlab("relevance")+
    ylab("publication counts") +
    scale_color_manual(values = c("red", "black","blue", "grey40"))+
   scale_shape_manual(values = c(8, 15, 8, 15))+
    my.theme+
  labs(color = "source")+
   scale_alpha_manual(values=c(0.8, 0.8, 0.8,0.5))+
  theme(legend.position="right")


plot_relevance_source

#ggsave(here::here("figures/plot_relevance_source.png"), height = 5, width = 8)

```

### 10.3 Data Format

```{r}

dataset_sc = dataset[dataset$source == "semantic_scholar",]

dataset1 <- dataset_sc[dataset_sc$dataset_location != "no",]
dataset1 <- dataset_sc[dataset_sc$dataset_format != "",]

plot_data.type_format(dataset1)


```

### 9.4 Source of information across time

```{r}

dataset_st <- dataset |>
  dplyr::filter(dataset_relevance != "No dataset") |>
  dplyr::filter(dataset_relevance != "No access") |>
  dplyr::filter(dataset_relevance != "X") |>
  dplyr::filter(dataset_relevance != "") |>
  dplyr::filter(!is.na(dataset_relevance))


```


```{r}
df_plot_source_time <- as.data.frame(table(dataset_st$publication_year,dataset_st$source ))

colnames(df_plot_source_time) <- c("year", "source", "N")

df_plot_source_time$N <- as.numeric(df_plot_source_time$N)


plot_source_time <- ggplot(df_plot_source_time, aes(x = year, y = N, group = source, color = source)) +
  geom_line(size = 1.2, alpha = 0.8)+
    theme_bw()+
  my.theme+
  theme(axis.text.x = element_text(angle = 0, hjust=0.95,vjust=0.2, size = 9))+
  ylab("publication counts") +
  scale_x_discrete(guide = guide_axis(n.dodge=2))+
    scale_color_manual(values = c("semantic_scholar" = "black", "dryad" = "red", "zenodo" = "blue"),
                     labels = c("dryad", "semantic scholar", "zenodo")) +
  theme(legend.position="right")+
  ggtitle("")

plot_source_time

```

```{r}

plots_semantic_repos <- ggarrange(
  plot_relevance_source,
  plot_source_time,
  labels = c("A", "B"),
  font.label = list(size = 20),
  ncol = 1,
  nrow = 2
)

plots_semantic_repos

#ggsave(here::here("figures/semantic_repos_comparison.png"), height = 9, width = 9)

```


