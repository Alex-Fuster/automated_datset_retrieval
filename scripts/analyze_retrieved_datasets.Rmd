---
title: "Analyses for Evaluating the feasibility of automating dataset retrieval for biodiversity monitoring"
output: html_notebook
Authors: Alexandre Fuster-Calvo, Sarah Valentin
---


**Script description:** This script manipulates the raw data of the retrieved datasets to show summary tables and figures.

```{r}
library(dplyr)
library(reshape)
library(ggplot2)
library(hrbrthemes)
library(ggpubr)
library(tidyr)
library(stringr)
library(ggrepel)
library(readxl)

source("Functions.R")
```



Some parameters for plotting:

```{r}
my.theme<-theme(axis.text=element_text(size=15),
        axis.title = element_text(size = 17),
        legend.text=element_text(size=10),
        legend.title = element_text(size=12),
        plot.title = element_text(face="bold",size=14,margin=margin(0,0,20,0),hjust = 0.5),
        axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)),
        axis.title.x = element_text(margin = margin(t = 15, r = 0, b = 0, l = 0)),
        panel.background = element_rect(fill = 'white'))

```




#### Read data

```{r}

dataset <- read_excel("../data/dataset.xlsx")

dataset <- dataset %>%
  filter(!(source %in% c("semantic_scholar", "referenced")))

```



Overlap between queries

```{r}

query_sets <- lapply(0:10, function(i) {
  query_ids <- which(grepl(paste0("\\b", i, "\\b"), dataset$id_query))
  return(query_ids)
})


# Initialize a matrix to store the overlap percentages
overlap_matrix <- matrix(0, nrow = 11, ncol = 11)

# Calculate the overlap percentage between each pair of queries
for (i in 1:length(query_sets)) {
  for (j in 1:length(query_sets)) {
    if (i != j) {
      overlap <- length(intersect(query_sets[[i]], query_sets[[j]]))
      overlap_percentage <- (overlap / (length(query_sets[[i]]) + length(query_sets[[j]]) - overlap)) * 100
      overlap_matrix[i, j] <- overlap_percentage
    }
  }
}

# Print the overlap matrix
overlap_matrix = round(overlap_matrix, 1)

query_names = c(
"survey + species",
"time series + species",
"inventory + species",
"species",
"abundance + species",
"occurrence + species",
"population + species",
"sites + species",
"sampling + species",
"collection + species",
"density + species"
  
)

colnames(overlap_matrix) = query_names
rownames(overlap_matrix) = query_names

#colnames(overlap_matrix) = as.character(1:11)
#rownames(overlap_matrix) = as.character(1:11)


upper_triangle <- overlap_matrix
upper_triangle[lower.tri(upper_triangle)] <- 0


upper_triangle_df <- as.data.frame(as.table(upper_triangle))
names(upper_triangle_df) <- c("row", "col", "value")
upper_triangle_df <- upper_triangle_df[upper_triangle_df$row != upper_triangle_df$col, ]

# Plot triangle heatmap
plot_overlap_queries = ggplot(upper_triangle_df, aes(x = col, y = row, fill = value)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  labs(x = NULL, y = NULL, fill = "% overlap")

ggsave("../figures/plot_overlap_queries.png", height = 5, width = 6)

```




Count Valid/non-valid datasets:

```{r}

table(dataset$valid_yn)

```

count reasons for non-valid assignment:

```{r}

table(dataset$reason_non_valid[which(dataset$valid_yn=="no")])
```

Select only relevant datasets

```{r}
dataset <- dataset[dataset$dataset_relevance != "",]
dataset <- dataset %>% dplyr::filter(valid_yn == "yes")
dataset$dataset_relevance <- as.factor(dataset$dataset_relevance)

dataset$id_query  <- stringr::str_trim(dataset$id_query)
dataset$dataset_relevance  <- str_trim(dataset$dataset_relevance)

head(dataset)
```

# 1. Number of datasets and relevance categories

```{r}

table(dataset$dataset_relevance)

df_N_relevance <- count_by_relevance(dataset)

df_N_relevance %>% 
  mutate(percent = N/sum(N)*100)
```

# 2. Queries performance

### 2.1. N publications and relevance categories per query

```{r}

convert_query = data.frame("id_query" = as.character(seq(0,10)), "query" = c(
"survey + species",
"time series + species",
"inventory + species",
"species",
"abundance + species",
"occurrence + species",
"population + species",
"sites + species",
"sampling + species",
"collection + species",
"density + species"
  
))


```

```{r}

#split rows in function of character comas

dataset_q <- dataset %>%               
  separate_rows(id_query, sep=",") 


dataset_q <- merge(dataset_q, convert_query, by.all="id_query")


dataset_q$query  <- factor(dataset_q$query,
                           levels= c("species", "occurrence + species",
                                     "inventory + species", "collection + species",
                                     "sampling + species", "survey + species" , 
                                     "population + species", "sites + species", 
                                     "density + species", "abundance + species",
                                     "time series + species" ))


df_queries_counts_ind <- dataset_q %>% 
  group_by(dataset_relevance, query) %>% 
  summarise(n = n()) 

df_queries_counts_ind <- df_queries_counts_ind %>% 
  dplyr::filter(dataset_relevance %in% c("X", "L", "M", "H")) %>% 
  mutate(dataset_relevance = factor(dataset_relevance))


df_queries_counts_ind

```

Plot the results:

```{r}


plot_queries_relevance_counts <- ggplot(df_queries_counts_ind, 
                                          aes(x=query, y=n, group = dataset_relevance, 
                                              color = dataset_relevance,shape=dataset_relevance )) +
  geom_segment( aes(x=query ,xend=query, y=0, yend=max(n)), color="grey") +
    geom_point(size=4, alpha = 0.8) +
    coord_flip() +
    # theme_ipsum() +
    theme(
      panel.grid.minor.y = element_blank(),
      panel.grid.major.y = element_blank(),
      legend.position="top"
    ) +
    xlab("Query ID")+
    ylab("publications counts") +
    scale_color_manual(name = "dataset relevance",
                       values = c( "red","purple2", "dodgerblue", "black"))+
    scale_shape_manual(name = "dataset relevance", 
                       values = c(19, 19, 19, 1))+
    my.theme



plot_queries_relevance_counts

```

### 2.2. F SCORE


```{r}

df_zscores_queries <- calculate_z.score_queries(df = dataset)

df_zscores_queries$Fscore <- round(df_zscores_queries$Fscore, 2)
df_zscores_queries$Precision <- round(df_zscores_queries$Precision, 2)
df_zscores_queries$Recall <- round(df_zscores_queries$Recall, 2)


df_zscores_queries

write.table(df_zscores_queries, file = "df_zscores_queries.txt", sep = ",", quote = FALSE, row.names = F)

```

Plot results:

```{r}

mid = mean(df_zscores_queries$Fscore)

plot_queries_scores <- ggplot(df_zscores_queries, aes(x = Precision, y = Recall, colour = Fscore)) +
  geom_point(size = 10)+
  geom_label_repel(aes(label = query),alpha = 0.75, 
                   label.padding=.1)+
  scale_color_gradient2(midpoint=mid, low="dodgerblue", mid="purple2",
                     high="red", space ="Lab" )+
  theme_bw()+
  my.theme

plot_queries_scores

```

```{r}

combined_plot_queries <- ggarrange(plot_queries_relevance_counts,
                                   plot_queries_scores, 
                                   nrow = 1,
                                   ncol = 2)

combined_plot_queries

ggsave("../figures/combined_plot_queries.png",height = 6,width = 13)

```



# 3. Temporal range and duration

Discard datasets with negligible relevance (n = 16) for all the analyses from here.

```{r}
dataset <- dataset[dataset$dataset_relevance != "X",]


# how many datasets with temporal range information

print(paste(length(which(dataset$temporal_range_position == "not given")), "publications without temporal range data"))
```

### 3.1 Temporal range

```{r}

# Select variables of interest

dataset_temp_range <- dataset[,c("url", "temp_range_i", "temp_range_f", "time_series")]

# Eliminate Nas

dataset_temp_range <- dataset_temp_range[-which(is.na(dataset_temp_range$temp_range_i)),]

dataset_temp_range <- as.data.frame((dataset_temp_range))

dataset_temp_range$temp_range_i <- as.numeric(dataset_temp_range$temp_range_i)
dataset_temp_range$temp_range_f <- as.numeric(dataset_temp_range$temp_range_f)

print(paste(nrow(dataset_temp_range), "with temporal range data"))


# Eliminate outlier

dataset_temp_range <- dataset_temp_range[-which(dataset_temp_range$temp_range_i == -20000),]

dataset_temp_range[which(dataset_temp_range$temp_range_i == dataset_temp_range$temp_range_f),"temp_range_f"] <- dataset_temp_range[which(dataset_temp_range$temp_range_i == dataset_temp_range$temp_range_f),"temp_range_f"]+0.5

# cut lower limit range for outlier

dataset_temp_range$temp_range_i[which(dataset_temp_range$temp_range_i < 1930)] <- 1930





```

Plot the results:

```{r}

p_temp_range <- ggplot(dataset_temp_range, aes(y=url, color = time_series)) +
  geom_segment(aes(x=temp_range_i, xend=temp_range_f, y=url, yend=url), linewidth=3)+
  xlab("year") +
  ylab ("datasets")+
  #theme_bw() +
  my.theme +
  theme(axis.text.y=element_blank())+
  scale_color_manual(values = c("gray37", "#F8766D"))+
  theme(legend.position = "none") +
  xlim(1930, round(max(dataset_temp_range$temp_range_f),0))+
  geom_label(
    label="1875", 
    x=1930,
    y=5,
    #label.padding = unit(0.2, "lines"), # Rectangle size around label
    label.size = 0.1,
    color = "black"
   # fill="white"
  )

p_temp_range

#ggsave("plots_repo/temporal_range.png", height = 7, width = 7)

```

### 3.2 Temporal duration counts

How many publications without temporal duration data?

```{r}

#nNa <- count_not.reported_temporal.duration(dataset)

print(paste(length(which(dataset$temporal_duration_position == "not given")), "publications without temporal duration data"))


```

Publication counts by temporal duration (years):

```{r}
  
df_duration_counts <- count_durations(df = dataset, order_by = "counts")

df_duration_counts
```

Plot the results:

```{r}
plot_temp_duration <- plot_duration_counts(df = df_duration_counts, 
                                           counts_Na = nNa)

plot_temp_duration

#ggsave("plots_repo/plot_temp_duration.png", height = 5, width = 9)

```

Average duration (for those with data):

```{r}

dataset_temp_duration <- subset(dataset, 
                                  temporal_duration_y > 0 | temporal_duration_y == "not given",
                                  select = c(temporal_duration_y,id_query))
  
  dataset_temp_duration$temporal_duration_y <- as.numeric(dataset_temp_duration$temporal_duration_y)
  

print(paste("mean of",
            round(mean(na.omit(dataset_temp_duration$temporal_duration_y)),digits = 1),
            "years"))
```

# 4. Spatial range

### 4.1 count spatial range publications

Publications that cant be accessed are not counted.

How many publications without spatial range data?

```{r}

n_not_reported <- count_not.reported_spatial_range(dataset)

print(paste(n_not_reported, "publications without spatial range data"))

```

Average spatial range:

```{r}

dataset1 <- dataset[dataset$dataset_relevance != "cant access",]
  
  dataset1$dataset_relevance <- as.factor(dataset1$dataset_relevance)
  
  spatial_range_km2_vec <- dataset1$spatial_range_km2[dataset1$spatial_range_km2 != ""]
  
  spatial_range_km2_vec <- spatial_range_km2_vec[!is.na(spatial_range_km2_vec)]
  
  spatial_range_km2_vec <- as.numeric(spatial_range_km2_vec) 


print(paste("mean of",
            round(mean(na.omit(spatial_range_km2_vec)), digits = 0),
            "km2"))
```

Plot the results: Spatial ranges are divided according to the thresholds established to determine a low, moredate and high spatial range: \<5000, 500-15000, \>15000

```{r}

plot_spatial_range_counts <- plot_spat.range_counts(dataset)+
  coord_flip()

plot_spatial_range_counts
  

#ggsave("plots_repo/plot_spatial_range_counts.png", height = 6, width = 6)

```





```{r}
print(paste(length(which(dataset$geospatial_info_repo_page_text == "not given")), "publications without spatial range data in the repository"))

```





#### Temporal duration, spatial range, relevance

```{r}

plot_spatial_temporal_relevance <- plot_spat_temp_relevance(df = dataset)

plot_spatial_temporal_relevance

#ggsave("plots_repo/plot_spatial_temporal_relevance.png", height = 6, width = 9)

```

# 5. EBV data types

```{r}

df_data_type_counts <- compute_df_data.type(df = dataset)

df_data_type_counts 

```

Plot the results

```{r}

plot_data_type <- plot_data.type_counts(df_data_type_counts)+
  coord_flip()

plot_data_type

#ggsave("plots_repo/plot_data_type.png", height = 6, width = 9)

```

### Combine plots

```{r}

plot_combined_corpus <- ggarrange(
p_temp_range,
plot_spatial_temporal_relevance,
plot_data_type,
plot_spatial_range_counts,
nrow = 2,
ncol = 2,
  labels = c("a", "b", "c","d"),
font.label = list(size = 24),
heights = c(1,0.6))

plot_combined_corpus

ggsave("../figures/plot_combined_corpus.png", height = 10, width = 12)
```

# 6. Data format

Those datasets in the repository that are relevance category X don't have format information.

```{r}

plot_data_format_counts <- plot_data.type_format(dataset)

plot_data_format_counts

#ggsave("plots_repo/plot_data_format_counts.png", height = 7, width = 9)


```



# 8. Location of information - features

### 8.1 % data type in abstract and title

Synonyms for the different EBV data type categories:

```{r}
df_dataset_types <- read.csv("../data/dataset_types.csv", sep = ",")
df_dataset_types
```

```{r}
df_dataset_types[nrow(df_dataset_types)+1,] <- c("presence-absence", "detection", "synonym")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("presence-absence", "capture", "synonym")

df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "16S", "methods")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "18S", "methods")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "barcodes", "methods")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "haplotypes", "methods")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "eDNA", "methods")
df_dataset_types[nrow(df_dataset_types)+1,] <- c("EBV genetic analyses", "SNPs", "methods")

df_dataset_types
```

```{r}
dataset <- read_excel("../data/dataset.xlsx")
dataset <- dataset %>%
  filter(!(source %in% c("semantic_scholar", "referenced")))
dataset <- dataset[dataset$dataset_relevance != "",]
dataset <- dataset %>% dplyr::filter(valid_yn == "yes")

## Only relevant datasets:

dataset_rel <- dataset[dataset$dataset_relevance != "X",]



url <- c()
dataset_type <- c()
keyword_abs <- list()
keyword_title <- list()
#keyword_type <- c()
in_title <- c()
in_abstract <- c()


for (i in 1:nrow(dataset_rel)) {
  
  
  
  dataset_type[i] <- dataset_rel[i, "data_type"]
  url[i] <- dataset_rel[i, "url"]
  
  
  
  
  # search on the abstract and note the list of keywords that match the dataset types

  keyword_abs[[i]] <- unique(get_keywords(input_string = dataset$full_text[i], 
               dataset_types =  df_dataset_types))
  
  # if the list of keywords has 1 or more entry, then note that we found information in the abstract
  
  if(length(keyword_abs[i][!sapply(keyword_abs[i], is.null)]) == 0){
    
    in_abstract[i] <- "no"
    
  } else if (length(keyword_abs[i][!sapply(keyword_abs[i], is.null)]) > 0){
    
    in_abstract[i] <- "yes"
    
  }
  
  
  

  # search on the title and note the list of keywords that match the dataset types

  keyword_title[[i]] <- unique(get_keywords(input_string = dataset_rel$title[i], 
               dataset_types =  df_dataset_types))
  
  # if the list of keywords has 1 or more entry, then note that we found information in the abstract
  
  if(length(keyword_title[i][!sapply(keyword_title[i], is.null)]) == 0){
    
    in_title[i] <- "no"
    
  } else if (length(keyword_title[i][!sapply(keyword_title[i], is.null)]) > 0){
    
    in_title[i] <- "yes"
    
  } 
  
  
  
}


dataset_rel$data.type_in_abstract <- in_abstract
dataset_rel$data_type_in_title <- in_title



print(paste(length(which(in_abstract == "yes")), 
            "with dataset type or synonym explicit in the abstract, out of", length(in_abstract)))

print(paste("so", 
      round(length(which(in_abstract == "yes"))/length(in_abstract)*100, 1),
"%"))

print(paste(length(which(in_title == "yes")), 
            "with dataset type or synonym explicit in the title, out of", length(in_title)))

print(paste("so", 
      round(length(which(in_title == "yes"))/length(in_title)*100, 1),
"%"))



```

### 8.2 Temporal range and duration, spatial range, species, and data type location

```{r}


df_features.l <- dataset_rel[,c("temporal_range_position", "temporal_duration_position", "spatial_range_position", "data.type_in_abstract", "data_type_in_title")]

# add id

df_features.l$id <- c(1:nrow(df_features.l))



# separate by commas

df_features.l1 <- df_features.l %>%               
  separate_rows(temporal_range_position, sep=",") %>% 
  separate_rows(temporal_duration_position, sep=",") %>% 
  separate_rows(spatial_range_position, sep=",")



# Homogenize levels

levels(as.factor(df_features.l1$species_location))


df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == " source link")] <- "repository text"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == "source link")] <- "repository text"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == "source link abstract")] <- "repository text"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == " dataset")] <- "dataset"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == " source publication text")] <- "article"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == "source publication text")] <- "article"
df_features.l1$temporal_range_position[which(df_features.l1$temporal_range_position == "no")] <- "not given"



df_features.l1$temporal_duration_position[which(df_features.l1$temporal_duration_position == "source link")] <- "repository text"
df_features.l1$temporal_duration_position[which(df_features.l1$temporal_duration_position == "source link abstract")] <- "repository text"
df_features.l1$temporal_duration_position[which(df_features.l1$temporal_duration_position == "source publication text")] <- "article"
df_features.l1$temporal_duration_position[which(df_features.l1$temporal_duration_position == "no")] <- "not given"



df_features.l1$spatial_range_position[which(df_features.l1$spatial_range_position == "source link")] <- "repository text"
df_features.l1$spatial_range_position[which(df_features.l1$spatial_range_position == "source link abstract")] <- "repository text"
df_features.l1$spatial_range_position[which(df_features.l1$spatial_range_position == "source publication text")] <- "article"
df_features.l1$spatial_range_position[which(df_features.l1$spatial_range_position == "no")] <- "not given"


df_features.l1

```

How many with all the features readily accessible (in repository text):

```{r}
n_all <- nrow(na.omit(df_features.l1[ 
                   df_features.l1$data.type_in_abstract == "yes" & 
                   df_features.l1$temporal_range_position == 'repository text' &
                   df_features.l1$spatial_range_position == 'repository text',]))

print(paste(n_all, "with all the features readily accessible (in the repository text) - a", round(n_all/nrow(dataset_rel)*100, 3),"%"))

```

How many with at least one feature accessible

```{r}

df_features.l2 <- df_features.l1[!is.na(df_features.l1$data.type_in_abstract),]

df_features.l2 <- df_features.l1[ 
  df_features.l1$data_type_in_title == "yes" |
                   df_features.l1$data.type_in_abstract == "yes" |
                   df_features.l1$temporal_range_position == 'repository text' |
                   df_features.l1$spatial_range_position == 'repository text', ]

df_features.l2 <- df_features.l2[!is.na(df_features.l2$data.type_in_abstract),]
n_any <- length(unique(df_features.l2$id))

print(paste(n_any, "with at least one feature readily accessible (in the repository text) - a", round(n_any/nrow(dataset_rel)*100, 3),"%"))

```


```{r}


df_locations_plot <- count_position_features(dataset)

df_locations_plot <- df_locations_plot[!is.na(df_locations_plot$location), ]



plot_location_features <- ggplot(df_locations_plot, aes(x=location, y = Freq, group = feature)) +
   geom_segment( aes(x=location ,xend=location, y=0, yend=max(Freq)), color="grey") +
    geom_point(aes(shape = feature),size=4, alpha = 0.8) +
    coord_flip() +
  theme_bw() +
  my.theme+
  #scale_color_manual(values = c("deepskyblue2","firebrick1","indianred4"))+
  scale_shape_manual(values = c(16,8,2))+
  ylab("publication counts")+
  theme(legend.position = "top")

plot_location_features

ggsave("plots_repo/location_features.png", height = 5, width = 6.5)

```

#9. Spatial information format

```{r}

# Eliminate Nas

geospatial_info_article_text <- dataset$geospatial_info_article_text[-which(is.na(dataset$geospatial_info_article_text))]

geospatial_info_dataset <- dataset$geospatial_info_dataset[-which(is.na(dataset$geospatial_info_dataset))]

geospatial_info_repo_page_text <- dataset$geospatial_info_repo_page_text[-which(is.na(dataset$geospatial_info_repo_page_text))]


# Separate by commas

geospatial_info_article_text  <- unlist(strsplit(geospatial_info_article_text,","))

geospatial_info_dataset  <- unlist(strsplit(geospatial_info_dataset,","))

geospatial_info_repo_page_text  <- unlist(strsplit(geospatial_info_repo_page_text,","))



# Homogenize names

## column geospatial_info_article_text

geospatial_info_article_text[which(geospatial_info_article_text == " administrative unit")] <- "administrative unit"
geospatial_info_article_text[which(geospatial_info_article_text == " range coordites")] <- "range coordinates"
geospatial_info_article_text[which(geospatial_info_article_text == " site coordites")] <- "site coordinates"
geospatial_info_article_text[which(geospatial_info_article_text == "site coordites")] <- "site coordinates"
geospatial_info_article_text[which(geospatial_info_article_text == " geological feature me")] <- "geographic feature"
geospatial_info_article_text[which(geospatial_info_article_text == "geological feature me")] <- "geographic feature"
geospatial_info_article_text[which(geospatial_info_article_text == " Map")] <- "Map"
geospatial_info_article_text[which(geospatial_info_article_text == "Map")] <- "map"
geospatial_info_article_text[which(geospatial_info_article_text == "administration unit")] <- "administrative unit"
geospatial_info_article_text[which(geospatial_info_article_text == "Administrative unit")] <- "administrative unit"
geospatial_info_article_text[which(geospatial_info_article_text == "no")] <- "not given"


## column geospatial_info_dataset

geospatial_info_dataset[which(geospatial_info_dataset == " site coordites")] <- "site coordinates"
geospatial_info_dataset[which(geospatial_info_dataset == "  site coordites")] <- "site coordinates"
geospatial_info_dataset[which(geospatial_info_dataset == "site coordites")] <- "site coordinates"
geospatial_info_dataset[which(geospatial_info_dataset == "sample coordites")] <- "sample coordinates"
geospatial_info_dataset[which(geospatial_info_dataset == " sample coordites")] <- "sample coordinates"
geospatial_info_dataset[which(geospatial_info_dataset == " administrative unit")] <- "administrative unit"
geospatial_info_dataset[which(geospatial_info_dataset == " site IDs")] <- "site IDs"
geospatial_info_dataset[which(geospatial_info_dataset == " IDs")] <- "site IDs"
geospatial_info_dataset[which(geospatial_info_dataset == " geographic feature")] <- "geographic feature"
geospatial_info_dataset[which(geospatial_info_dataset == "no")] <- "not given"



## column geospatial_info_repo_page_text

geospatial_info_repo_page_text[which(geospatial_info_repo_page_text == "geological feature me")] <- "geographic feature"
geospatial_info_repo_page_text[which(geospatial_info_repo_page_text == "Administrative unit")] <- "administrative unit"
geospatial_info_repo_page_text[which(geospatial_info_repo_page_text == "no")] <- "not given"

```

```{r}

# Make dataframe with counts

location <- rep("article text", times = length(geospatial_info_article_text))

df_article <- data.frame(geospatial_info_article_text, location)

location <- rep("repository page", times = length(geospatial_info_repo_page_text))

df_repo<- data.frame(geospatial_info_repo_page_text, location)

location <- rep("dataset", times = length(geospatial_info_dataset))

df_dataset <- data.frame(geospatial_info_dataset, location)

colnames(df_article) <- c("information", "location")
colnames(df_repo) <- c("information", "location")
colnames(df_dataset) <- c("information", "location")

df_locations <- rbind(df_article,df_repo,df_dataset)

df_locations$information[which(df_locations$information == "site IDs") ] <- "sites IDs"
df_locations$information[which(df_locations$information == "site coordites") ] <- "site coordinates"
df_locations$information[which(df_locations$information == "Map") ] <- "map"
df_locations$information[which(df_locations$information == "geologial feature") ] <- "geographic feature"
df_locations$information[which(df_locations$information == "geographical feature") ] <- "geographic feature"

```


Plot results

```{r}

df_locations <- as.data.frame(table(df_locations))


df_locations$location <- factor(df_locations$location, levels=c("article text", "repository page", "dataset"))

df_locations$information <- factor(df_locations$information, levels=c("not given", "sites IDs", "map", "administrative unit", "geographic feature", "distribution model", "range coordinates", "site coordinates", "sample coordinates"))

df_filtered <- df_locations %>% filter(!is.na(information))

plot_location_type_geoinfo <- ggplot(df_filtered, aes(x=information, y = Freq, group = location, color = location)) +
   geom_segment( aes(x=information ,xend=information, y=0, yend=max(Freq)), color="grey") +
    geom_point(size=4, alpha = 0.5, aes(shape = location)) +
    coord_flip() +
  theme_bw() +
  my.theme+
  scale_shape_manual(values = c(15,8,21))+
  scale_color_manual(values = c("black", "black", "black"))+
  ylab("publication counts")+
  xlab("geospatial information")+
  theme(legend.position = "top")


plot_location_type_geoinfo

  
ggsave("plots_repo/location_type_geoinfo.png", height = 5, width = 7)


```



```{r}
plot_location_inf <- ggarrange(
  
  plot_location_features,
  plot_location_type_geoinfo,
  
  nrow = 1,
  ncol = 2,
  
  labels = c("a", "b")
  
)

plot_location_inf


ggsave("plot_location_inf.png", height = 5, width = 13)

```



######################################################### 

# 10. Semantic Scholar

#### Read data

```{r}

dataset <- read_excel("../data/dataset.xlsx")

dataset_sc <- dataset[dataset$source == "semantic_scholar" & dataset$source != " ",]

```

```{r}

table(dataset_sc$valid_yn)

```

```{r}

table(dataset_sc$reason_non_valid[which(dataset_sc$valid_yn=="no")])
```





### 10.1. Number of datasets and relevance categories

select only valid publications

```{r}
dataset_sc <- dataset_sc %>% dplyr::filter(valid_yn == "yes")
```


Only Semantic Scholar

```{r}

df_N_relevance <- count_by_relevance(dataset_sc)

df_N_relevance %>% 
  mutate(percent = N/sum(N)*100)
```

### 10.2 Relevance counts by source


```{r}

dataset <- read_excel("../data/dataset.xlsx")

dataset <- dataset[which(dataset$dataset_relevance != ""),]
dataset <- dataset %>% dplyr::filter(valid_yn == "yes")

dataset$dataset_relevance[which(dataset$dataset_relevance == "cant access")] <- "No access"

df_rel_source <- count_relevance_by_source(df = dataset)

df_rel_source$repositories <- df_rel_source$dryad + df_rel_source$zenodo

df_rel_source


```

Plot the results:

```{r}

df_rel_source_melt <- melt(df_rel_source, id ="relevance")
colnames(df_rel_source_melt) <- c("relevance", "source", "value")
df_rel_source_melt$relevance[which(df_rel_source_melt$relevance== "cant access")]

plot_relevance_source <- ggplot(df_rel_source_melt, 
                                          aes(x=relevance, y=value, group = source, 
                                              color = source,
                                              alpha=source)) +
  scale_x_discrete(limits = rev(levels(df_rel_source_melt$relevance)))+
    geom_segment( aes(x=relevance ,xend=relevance, y=0, yend=max(value)), color="grey") +
    geom_point(aes(shape = source),size = 5) + #alpha = 0.8, 
    coord_flip() +
    # theme_ipsum() +
    theme(
      panel.grid.minor.y = element_blank(),
      panel.grid.major.y = element_blank(),
      legend.position="top"
    ) +
    xlab("relevance")+
    ylab("dataset counts") +
    scale_color_manual(values = c("red", "black","blue", "grey40"))+
   scale_shape_manual(values = c(8, 15, 8, 15))+
    my.theme+
  labs(color = "source")+
   scale_alpha_manual(values=c(0.8, 0.8, 0.8,0.5))+
  theme(legend.position="right")


plot_relevance_source

ggsave("plots_semantic_scholar/plot_relevance_source.png", height = 5, width = 8)

```

### 10.3 Data Format

```{r}

dataset_sc = dataset[dataset$source == "semantic_scholar",]

dataset1 <- dataset_sc[dataset_sc$dataset_location != "no",]
dataset1 <- dataset_sc[dataset_sc$dataset_format != "",]

plot_data.type_format(dataset1)

#ggsave("plots_semantic_scholar/formats_semschol.png", height = 5, width = 8)
  

```

### 10.4 Source of information across time

```{r}

dataset <- read_excel("../data/dataset.xlsx")

dataset <- dataset %>% dplyr::filter(valid_yn == "yes")
dataset$dataset_relevance[which(dataset$dataset_relevance == "cant access")] <- "No access"


dataset_st <- dataset[dataset$dataset_relevance != "No dataset",]
dataset_st <- dataset_st[dataset_st$dataset_relevance != "No access",]
dataset_st <- dataset_st[dataset_st$dataset_relevance != "X",]
dataset_st <- dataset_st[dataset_st$dataset_relevance != "",]
dataset_st <- dataset_st[!is.na(dataset_st$dataset_relevance),]

dataset_st$publication_year


```


```{r}
df_plot_source_time <- as.data.frame(table(dataset_st$publication_year,dataset_st$source ))

colnames(df_plot_source_time) <- c("year", "source", "N")

df_plot_source_time$N <- as.numeric(df_plot_source_time$N)


plot_source_time <- ggplot(df_plot_source_time, aes(x = year, y = N, group = source, color = source)) +
  geom_line(size = 1.2, alpha = 0.8)+
    theme_bw()+
  my.theme+
  theme(axis.text.x = element_text(angle = 0, hjust=0.95,vjust=0.2, size = 9))+
  ylab("N retrieved datasets") +
  scale_x_discrete(guide = guide_axis(n.dodge=2))+
    scale_color_manual(values = c("semantic_scholar" = "black", "dryad" = "red", "zenodo" = "blue"),
                     labels = c("dryad", "semantic scholar", "zenodo")) +
  theme(legend.position="right")

plot_source_time


#ggsave("plots_semantic_scholar/plot_source_time.png", height = 5, width = 10)

```

```{r}

plots_semantic_repos <- ggarrange(
  plot_relevance_source,
  plot_source_time,
  labels = c("a", "b"),
  font.label = list(size = 20),
  ncol = 1,
  nrow = 2
)

plots_semantic_repos

ggsave("emantic_repos_comparison.png", height = 9, width = 9)

```


# 11. Taxa (repos)

```{r}
library(forcats)

df_taxa <- read.csv("../data/df_taxa_fig.csv", header = TRUE,sep=",")

df_taxa$X1_10_spp[which(df_taxa$X1_10_spp == "Mammalia\xa0")] <- "Mammalia"
df_taxa$X1_10_spp[which(df_taxa$X1_10_spp == "Amphibia\xa0")] <- "Amphibia"
df_taxa$X1_10_spp[which(df_taxa$X1_10_spp == "Osteichthyes")] <- "Fish"

df_taxa_spp <- df_taxa[which(df_taxa$X1_10_spp != ""),]

df_taxa_spp$X1_10_spp <- as.factor(df_taxa_spp$X1_10_spp)

df_taxa_spp$dataset_relevance <- factor(df_taxa_spp$dataset_relevance, levels = c("H", "M", "L"))

plot_spp <- ggplot(df_taxa_spp, aes(x = X1_10_spp, group = dataset_relevance, fill = dataset_relevance)) +
  geom_bar(aes(x = forcats::fct_infreq(X1_10_spp), fill = dataset_relevance))+
  my.theme+
  coord_flip()+
    xlab("")+
    ylab("publications counts") +
    ggtitle("Species-level studies")+
    scale_fill_manual(name = "dataset relevance",
                       values = alpha(c("red","purple2", "dodgerblue"), .7))+
 # theme_bw()+
    my.theme


df_taxa$more_10spp[which(df_taxa$more_10spp == "Mammalia\xa0")] <- "Mammalia"
df_taxa$more_10spp[which(df_taxa$more_10spp == "Osteichthyes")] <- "Fish"
df_taxa_comm <- df_taxa[which(df_taxa$more_10spp != ""),]




df_taxa_comm$more_10spp <- as.factor(df_taxa_comm$more_10spp)
df_taxa_comm$n <- as.numeric(df_taxa_comm$n)

df_taxa_comm$n[which(df_taxa_comm$n == 1)] <- 2
df_taxa_comm$n[which(df_taxa_comm$n == 2)] <- 3

df_taxa_comm <- df_taxa_comm[order(-df_taxa_comm$n), ]


df_taxa_comm$dataset_relevance <- factor(df_taxa_comm$dataset_relevance, levels = c("H", "M", "L"))

plot_comm <- ggplot(df_taxa_comm, aes(x = more_10spp, y = n, fill = dataset_relevance)) +
   geom_bar(stat = "identity", position = position_dodge2(preserve = "total"),  color = "white")+
  coord_flip()+
  ggtitle("Community-level studies")+
    xlab("")+
    ylab("N taxa") +
    scale_fill_manual(name = "dataset relevance",
                       values = alpha(c("red","purple2", "dodgerblue"), .7))+
  scale_y_continuous(limits = c(0, max(df_taxa_comm$n)), breaks = c(25,50,75, 100, 125, 150, 175))+
 # theme_bw()+
    my.theme


plots_taxa <- ggarrange(plot_spp,
          plot_comm,
          common.legend = TRUE)

ggsave("plots_taxa.png", height = 8, width = 11)

```

